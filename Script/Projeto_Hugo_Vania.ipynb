{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SER-347 - Introdução à Programação para Sensoriamento Remoto\n",
    "\n",
    "## \tAnálise de respostas da vegetação ao longo de período de seca no semi-árido brasileiro 2010 - 2018 \n",
    "\n",
    "- Hugo Tameirão Seixas\n",
    "- Vania Maria de Oliveira\n",
    "\n",
    "\n",
    "# 1. Introdução\n",
    "O presente trabalho teve como objetivo avaliar a relação entre variáveis de vegetação obtidas dos produtos MODIS (Moderate-Resolution Imaging Spectroradiometer) com umidade do solo obtida do SMOS (Soil Moisture and Ocean Salinity), e precipitação obtida do CHIRPS (Climate Hazards Group InfraRed Precipitation with Station). A área de estudo está inserida no semi-árido brasileiro, na região de Petrolina-PE/Juazeiro-BA.A análise das variáveis será feita pelo o uso de séries temporais, que possibilitarão a observaço da condição da vegetação ao longo de anos com precipitação abaixo da média anual.\n",
    "\n",
    "Os produtos MODIS que serão utilizados são: MOD11A2.006, MOD15A2H.006, MOD13A3.006,MOD17A2H.006, MCD12Q1.006. Sendo que deles serão extraídos medidas de LST (Land Surface Temperature), LAI (Leaf Area Index), NDVI (Normalized Difference Vegetation Index), EVI (Enchanced Vegetation Index), e GPP (Gross Primary Production).\n",
    "\n",
    "<img src=\"Fluxograma.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =====================================================================================================================\n",
    "# Import libraries\n",
    "# =====================================================================================================================\n",
    "\n",
    "import requests as r\n",
    "import ftplib\n",
    "import cgi\n",
    "import json\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "import time\n",
    "import progressbar\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import datetime\n",
    "import shapely\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================================================\n",
    "# Part 1:Setup configuration\n",
    "# =====================================================================================================================\n",
    "sep = \"========================================================================================================================\"\n",
    "print(sep)\n",
    "\n",
    "#Inicial Recommendations\n",
    "print(\"To start the script it is necessary to define the working directory, in which all download files will be stored, \"\n",
    "      \"the extent coordinates of the area of study in decimal degrees (WGS84), \"\n",
    "      \"as well the username and password to access the ESA and APPEEARS portal in order to download SMOS data.\")\n",
    "print(\"\")\n",
    "print(\"IMPORTANT!! - It is is necessary to enable the API options to access APPEEARS data as shown in : \" \n",
    "      \"https://lpdaacsvc.cr.usgs.gov/appeears/help\")\n",
    "print(sep)\n",
    "\n",
    "#Enter Inicial information: File path, area of interest, username and password on the ESA and Appears websites\n",
    "try_again = True\n",
    "while try_again:\n",
    "    while True:\n",
    "        try:\n",
    "            wdir = input(\"Define working directory: \")  \n",
    "            os.chdir(wdir)\n",
    "            break\n",
    "        except:\n",
    "            print(\"Error setting the working directory\")\n",
    "\n",
    "    while True:\n",
    "        xbl = float(input(\"Define bottom left longitude: \"))\n",
    "        if (xbl > -180) and (xbl < 180):\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid longitude\")\n",
    "    while True:\n",
    "        ybl = float(input(\"Define bottom left latitude: \"))\n",
    "        if (ybl > -90) and (ybl < 90):\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid latitude\")\n",
    "    while True:\n",
    "        xur = float(input(\"Define upper right longitude: \"))\n",
    "        if (xur > -180) and (xur < 180) and (xur > xbl):\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid longitude\")\n",
    "    while True:\n",
    "        yur = float(input(\"Define upper right latitude: \"))\n",
    "        if (yur > -180) and (yur < 180) and (yur > ybl):\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid latiitude\")\n",
    "            \n",
    "    print(sep)\n",
    "    \n",
    "    #Longitude X list to create rectangle in plot | Latitude Y list to create rectangule in plot\n",
    "    x = [xbl, xbl, xur, xur, xbl] \n",
    "    y = [ybl, yur, yur, ybl, ybl]  \n",
    "    \n",
    "    #Load Basemap\n",
    "    stamen_terrain = cimgt.StamenTerrain() \n",
    "    \n",
    "    #Create figures to show where study area is located\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1, projection=stamen_terrain.crs)\n",
    "    ax.set_extent([xbl-10, xur+10, ybl-10, yur+10])\n",
    "    ax.add_image(stamen_terrain, 8)\n",
    "    ax.plot(x, y, color='red', linewidth=1, transform=cartopy.crs.PlateCarree())\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection=stamen_terrain.crs)\n",
    "    ax2.set_extent([xbl-1, xur+1, ybl-1, yur+1])\n",
    "    ax2.add_image(stamen_terrain, 9)\n",
    "    ax2.plot(x, y, color='red', linewidth=1, transform=cartopy.crs.PlateCarree())\n",
    "    \n",
    "    print(\"Checking setup:\")\n",
    "    print(\"Working directory set to: \", wdir)\n",
    "    print(\"Bottom left longitude = \", xbl)\n",
    "    print(\"Bottom left latitude = \", ybl)\n",
    "    print(\"Upper right longitude = \", xur)\n",
    "    print(\"Upper right latitude = \", yur)\n",
    "    print(sep)\n",
    "    print(\"Creating sample, please wait...\")\n",
    "    plt.show()\n",
    "    print(\"Done!\")\n",
    "    retry = input(\"Do you want to confirm the settings?(y/n)\")  # Option to rerun loop\n",
    "    if retry == \"n\":\n",
    "        try_again = True\n",
    "        print(\"Resetting setup settings...\")\n",
    "    elif retry == \"y\":\n",
    "        try_again = False\n",
    "        print(\"Setup settings confirmed!\")\n",
    "    else:\n",
    "        print(\"Invalid input. Resetting setup...\")\n",
    "        \n",
    "    print(sep)\n",
    "\n",
    "inAreas = input('Set area of interest method (1/2). -Note- Method 1 uses the Land Cover product from MODIS'\n",
    "                'to generate random points for the 4 biggest land class for the study area. Method 2 requires'\n",
    "                'a csv file named as \"land_use_points\" and must be inserted in the working directory. This csv'\n",
    "                'file must contain columns named LandUse/lat/lon. (Default = 1) ')    \n",
    "print('Method {0} was selected'.format(inAreas))\n",
    "print(sep)\n",
    "\n",
    "print(\"ESA sign in, if you don't have an account, access: https://eo-sso-idp.eo.esa.int/idp/umsso20/registration\")\n",
    "user_ESA = input(\"Insert your ESA username: \")\n",
    "password_ESA = getpass.getpass(\"Insert your ESA password: \")\n",
    "print(sep)\n",
    "\n",
    "print(\"APPEEARS sign in, if you don't have an account, access: https://lpdaacsvc.cr.usgs.gov/appeears/\")\n",
    "user_APPEEARS = input(\"Insert your APPEEARS username: \")\n",
    "password_APPEEARS = getpass.getpass(\"Insert your APPEEARS password: \")\n",
    "print(sep)\n",
    "\n",
    "print(\"Setup was succesfully done!\")\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "\n",
    "To start the script it is necessary to define the working directory, in which all download files will be stored, the extent coordinates of the area of study in decimal degrees (WGS84), as well the username and password to access the ESA and APPEEARS portal in order to download SMOS data.\n",
    "\n",
    "IMPORTANT!! - It is is necessary to enable the API options to access APPEEARS data as shown in : https://lpdaacsvc.cr.usgs.gov/appeears/help\n",
    "\n",
    "====================================================================================================================\n",
    "\n",
    "Define working directory: /home/hugo/Documents/Projeto\n",
    "\n",
    "Define bottom left longitude: -40.8 \n",
    "\n",
    "Define bottom left latitude: -9.65 \n",
    "\n",
    "Define upper right longitude: -40 \n",
    "\n",
    "Define upper right latitude: -8.77 \n",
    "\n",
    "====================================================================================================================\n",
    "\n",
    "Checking setup:\n",
    "\n",
    "Working directory set to:  /home/hugo/Documents/Projeto\n",
    "\n",
    "Bottom left longitude =  -40.8\n",
    "\n",
    "Bottom left latitude =  -9.65\n",
    "\n",
    "Upper right longitude =  -40.0\n",
    "\n",
    "Upper right latitude =  -8.77\n",
    "\n",
    "====================================================================================================================\n",
    "Creating sample, please wait...\n",
    "\n",
    "<img src=\"StudyArea.png\">\n",
    "\n",
    "Done!\n",
    "\n",
    "Do you want to confirm the settings?(y/n) y\n",
    "\n",
    "Setup settings confirmed!\n",
    "\n",
    "====================================================================================================================\n",
    "\n",
    "Set area of interest method (1/2). -Note- Method 1 uses the Land Cover product from MODISto generate random points for the 4 biggest land class for the study area. Method 2 requiresa csv file named as \"land_use_points\" and must be inserted in the working directory. This csvfile must contain columns named LandUse/lat/lon. (Default = 1) 2\n",
    "Method 2 was selected\n",
    "\n",
    "====================================================================================================================\n",
    "\n",
    "ESA sign in, if you don't have an account, access: https://eo-sso-idp.eo.esa.int/idp/umsso20/registration\n",
    "\n",
    "Insert your ESA username: HugoSeixas\n",
    "\n",
    "Insert your ESA password: ········\n",
    "\n",
    "====================================================================================================================\n",
    "\n",
    "APPEEARS sign in, if you don't have an account, access: https://lpdaacsvc.cr.usgs.gov/appeears/\n",
    "\n",
    "Insert your APPEEARS username: Htseixas\n",
    "\n",
    "Insert your APPEEARS password: ········\n",
    "\n",
    "====================================================================================================================\n",
    "Setup was succesfully done!\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =====================================================================================================================\n",
    "# Part 2: Create subfolders for each data that will be used\n",
    "# =====================================================================================================================\n",
    "\n",
    "print(sep)\n",
    "print(\"Creating sub folders and setting paths...\")\n",
    "\n",
    "# Create SMOS directory if not exist\n",
    "sdir = os.path.join(wdir, \"smos\") \n",
    "if not os.path.exists(sdir):\n",
    "    os.makedirs(sdir)\n",
    "print(sdir)\n",
    "\n",
    "# Create CHIRPS directory if not exist\n",
    "cdir = os.path.join(wdir, \"chirps\") \n",
    "if not os.path.exists(cdir):\n",
    "    os.makedirs(cdir)\n",
    "print(cdir)\n",
    "\n",
    "# Create MODIS directory if not exist\n",
    "mdir = os.path.join(wdir, \"modis\") \n",
    "if not os.path.exists(mdir):\n",
    "    os.makedirs(mdir)\n",
    "print(mdir)\n",
    "\n",
    "print(\"Sub folders created successfully!\")\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Creating sub folders and setting paths...\n",
    "\n",
    "/home/hugo/Documents/Projeto/smos\n",
    "\n",
    "/home/hugo/Documents/Projeto/chirps\n",
    "\n",
    "/home/hugo/Documents/Projeto/modis\n",
    "\n",
    "Sub folders created successfully!\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================================================================================\n",
    "# Part 3: Part 3 is subdivided into 3.1, 3.2 and 3.3 and correspond to the downloads and \n",
    "# processing of each product used in this work \n",
    "# ===========================================================================================================================================\n",
    "# =====================================================================================================================\n",
    "# Part 3.1 - Data Download SMOS\n",
    "# =====================================================================================================================\n",
    "\n",
    "# SMOS\n",
    "print(sep)\n",
    "print(\"Starting to download SMOS Soil Moisture data...\")\n",
    "print(sep)\n",
    "\n",
    "# Date to start and finish the download. SMOS product to download\n",
    "begin = \"2010-06-01\"  \n",
    "end = \"2018-12-31\" \n",
    "prod = \"MIR_SMUDP2\"  \n",
    "\n",
    "print(\"Start date: \", begin)\n",
    "print(\"End date date: \", end)\n",
    "print(\"Product: \", prod)\n",
    "print(sep)\n",
    "\n",
    "#Download SMOS data\n",
    "print(\"Downloading secp utility...\")\n",
    "os.system('wget -P ' + sdir + ' -nc  https://github.com/spinto/secp/raw/master/secp')  # Download secp script\n",
    "os.system('chmod +x ' + sdir + '/secp')  # Give execution permissions to secp script\n",
    "print(\"Done\")\n",
    "print(sep)\n",
    "\n",
    "# Loop to download files from ascending orbit\n",
    "for o in [\"ASCENDING\"]:  \n",
    "    \n",
    "    print(\"Downloading url list of {0} files ...\".format(o))\n",
    "    cmd1 = ('curl --data \"service=SimpleOnlineCatalogue&version=1.0&'\n",
    "           'request=search&format=text%2Fplain&pageCount=10&'\n",
    "           'query.nativeProductFormat=NetCDF+Format&'\n",
    "           'query.footprint.minlat={0}&'.format(ybl) +\n",
    "           'query.footprint.minlon={0}&'.format(xbl) +\n",
    "           'query.footprint.maxlat={0}&'.format(yur) +\n",
    "           'query.footprint.maxlon={0}&'.format(xur) +\n",
    "           'query.beginAcquisition.start={0}&'.format(begin) +\n",
    "           'query.beginAcquisition.stop={0}&'.format(end) +\n",
    "           'query.orbitDirection={0}&'.format(o) +\n",
    "           'query.productType={0}\"'.format(prod) +\n",
    "           ' https://smos-diss.eo.esa.int/socat/SMOS_Open/search > {0}'.format(os.path.join(sdir, \"file_url\")))\n",
    "    os.system(cmd1)  # Download url list in txt from a query\n",
    "    print(\"Done\")\n",
    "    \n",
    "    #Create MODIS directory if not exist\n",
    "    print(\"Downloading {0} files ...\".format(o))\n",
    "    odir = os.path.join(sdir, o) \n",
    "    # Create sub folders to store files of each orbit direction\n",
    "    if not os.path.exists(odir): \n",
    "        os.makedirs(odir)\n",
    "    cmd2 = ('{0}'.format(os.path.join(sdir, \"secp\")) +  # Run secp script to download files\n",
    "            ' -F {0}' .format(os.path.join(sdir, \"file_url\")) +  # Take txt file with list of url for download\n",
    "            ' -o {0} -C {1}:{2}'.format(odir, user_ESA, password_ESA) +  # Set local dir and user/password\n",
    "            ' -P 4') # Parallel workers\n",
    "    os.system (cmd2) # Download files\n",
    "    print(\"Done\")\n",
    "\n",
    "# Delete secp script and txt file\n",
    "os.remove('{0}'.format(os.path.join(sdir, \"secp\")))  \n",
    "os.remove('{0}'.format(os.path.join(sdir, \"file_url\")))\n",
    "\n",
    "# Delete user informations\n",
    "del user_ESA, password_ESA \n",
    "\n",
    "print(\"Download was successfull!\")\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Starting to download SMOS Soil Moisture data...\n",
    "\n",
    "====================================================================================================================\n",
    "\n",
    "Start date:  2010-06-01\n",
    "\n",
    "End date date:  2018-12-31\n",
    "\n",
    "Product:  MIR_SMUDP2\n",
    "\n",
    "====================================================================================================================\n",
    "Downloading secp utility...\n",
    "\n",
    "Done\n",
    "\n",
    "====================================================================================================================\n",
    "\n",
    "Downloading url list of ASCENDING files ...\n",
    "\n",
    "Done\n",
    "\n",
    "Downloading ASCENDING files ...\n",
    "\n",
    "Done\n",
    "\n",
    "Download was successfull!\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================================================\n",
    "# Part 3.2 - Data Download CHIRPS\n",
    "# =====================================================================================================================\n",
    "\n",
    "#Access to UCSB FTP for download\n",
    "print(sep)\n",
    "print('Starting to download CHIRPS Rainfall data...')\n",
    "print('Connecting to ftp access...')\n",
    "ftp = ftplib.FTP('ftp.chg.ucsb.edu')\n",
    "ftp.login()\n",
    "ftp.cwd('/pub/org/chg/products/CHIRPS-2.0/global_monthly/netcdf/')  \n",
    "flist = ftp.nlst()\n",
    "file = flist[0]\n",
    "size = ftp.size(file)\n",
    "\n",
    "# Set directory and file to receive downloaded data\n",
    "host = os.path.join(cdir, file)  \n",
    "local = open(host, 'wb')\n",
    "\n",
    "print('Download started...')\n",
    "\n",
    "#Progress bar components and configuration\n",
    "widgets = ['Downloading: ', progressbar.Percentage(), ' ',\n",
    "           progressbar.Bar(marker='#',left='[',right=']'),\n",
    "           ' ', progressbar.ETA(), ' ', progressbar.FileTransferSpeed()]  \n",
    "\n",
    "pbar = progressbar.ProgressBar(widgets = widgets, maxval = size)  \n",
    "pbar.start()\n",
    "\n",
    "# Define function to download data using progress bar\n",
    "def file_write(data):  \n",
    "    local.write(data)\n",
    "    global pbar\n",
    "    pbar += len(data)\n",
    "\n",
    "ftp.retrbinary('RETR ' + file, file_write)  \n",
    "\n",
    "# Close connection\n",
    "local.close()\n",
    "ftp.quit()  \n",
    "\n",
    "print(\"Download was successfull!\")\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Starting to download CHIRPS Rainfall data...\n",
    "\n",
    "Connecting to ftp access...\n",
    "\n",
    "Download started...\n",
    "<img src=\"Progress.png\">\n",
    "\n",
    "Download was successfull!\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================================================\n",
    "# Parte 3.3: Download and processing of MODIS data\n",
    "# ===================================================================================================================\n",
    "\n",
    "#Access to data will be done through appeears\n",
    "print(sep)\n",
    "print('Starting to download MODIS data...')\n",
    "print('Connecting to APPEEARS API...')\n",
    "api = 'https://lpdaacsvc.cr.usgs.gov/appeears/api/'\n",
    "\n",
    "#We will use the previously entered username and password.\n",
    "token_response = r.post('{}login'.format(api), auth=(user_APPEEARS, password_APPEEARS)).json()\n",
    "\n",
    "del user_APPEEARS, password_APPEEARS\n",
    "\n",
    " # MODIS products to be downloaded\n",
    "print('Setting products to download...')\n",
    "prods = ['MOD11A2.006', 'MOD15A2H.006', 'MOD13A3.006',\n",
    "         'MOD17A2H.006', 'MCD12Q1.006'] \n",
    "\n",
    "# MODIS layers to be downloaded\n",
    "print('Setting layers to download...')\n",
    "layers = [(prods[0], 'LST_Day_1km'), (prods[1], 'Lai_500m'),\n",
    "          (prods[2], '_1_km_monthly_NDVI'), (prods[2], '_1_km_monthly_EVI'),\n",
    "          (prods[3], 'Gpp_500m'), (prods[4], 'LC_Type1')]  \n",
    "\n",
    "prodLayer = []\n",
    "for l in layers:\n",
    "    prodLayer.append({\"layer\": l[1], \"product\": l[0]})\n",
    "\n",
    "token = token_response['token']\n",
    "head = {'Authorization': 'Bearer {}'.format(token)}\n",
    "\n",
    "# Set area for download based on giver coordinates\n",
    "print('Setting area to download...')\n",
    "study_area = shapely.geometry.box(xbl, ybl, xur, yur)  \n",
    "crs = {'init': 'epsg:4326'}\n",
    "study_area = gpd.GeoDataFrame(index=[0], geometry=[study_area], crs=crs)\n",
    "study_area = study_area[0:].to_json()\n",
    "study_area = json.loads(study_area)\n",
    "\n",
    "task_name = 'ser_347'\n",
    "task_type = 'area'\n",
    "proj = 'geographic'\n",
    "outFormat = \"netcdf4\"\n",
    "startDate = \"06-01-2010\"\n",
    "endDate = '12-31-2018'\n",
    "recurring = False\n",
    "\n",
    "print('Creating new task...')\n",
    "task = {'task_type': task_type, 'task_name': task_name,\n",
    "        'params': {'dates': [{'startDate': startDate, 'endDate': endDate}],\n",
    "                   'layers': prodLayer,\n",
    "                   'output': {'format': {'type': outFormat}, 'projection': proj},\n",
    "                   'geo': study_area}}\n",
    "\n",
    "task_response = r.post('{}task'.format(api), json=task, headers=head).json()\n",
    "\n",
    "params = {'limit': 2, 'pretty': True}\n",
    "\n",
    "tasks_response = r.get('{}task'.format(api), params=params, headers=head).json()\n",
    "\n",
    "task_id = task_response['task_id']\n",
    "status_response = r.get('{}status/{}'.format(api, task_id), headers=head).json()\n",
    "\n",
    "print('Waiting for task processing at APPEEARS...')\n",
    "\n",
    "#Check task status for every 5 minutes\n",
    "starttime = time.time()\n",
    "while r.get('{}task/{}'.format(api, task_id), headers=head).json()['status'] != 'done':\n",
    "    print(r.get('{}task/{}'.format(api, task_id), headers=head).json()['status'])\n",
    "    time.sleep(300.0 - ((time.time() - starttime) % 300.0)) \n",
    "print(r.get('{}task/{}'.format(api, task_id), headers=head).json()['status'])\n",
    "\n",
    "bundle = r.get('{}bundle/{}'.format(api, task_id)).json()\n",
    "\n",
    "print('Starting download...')\n",
    "files = {}\n",
    "for f in bundle['files']:\n",
    "    files[f['file_id']] = f['file_name']\n",
    "for f in files:\n",
    "    dl = r.get('{}bundle/{}/{}'.format(api, task_id, f), stream=True)\n",
    "    filename = os.path.basename(cgi.parse_header(dl.headers['Content-Disposition'])[1]['filename'])\n",
    "    filepath = os.path.join(mdir, filename)\n",
    "    with open(filepath, 'wb') as f:\n",
    "        for data in dl.iter_content(chunk_size=8192):\n",
    "            f.write(data)\n",
    "\n",
    "print(\"Download was successfull!\")\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Starting to download MODIS data...\n",
    "\n",
    "Connecting to APPEEARS API...\n",
    "\n",
    "Setting products to download...\n",
    "\n",
    "Setting layers to download...\n",
    "\n",
    "Setting area to download...\n",
    "\n",
    "Creating new task...\n",
    "\n",
    "Waiting for task processing at APPEEARS...\n",
    "\n",
    "processing\n",
    "\n",
    "processing\n",
    "\n",
    "processing\n",
    "\n",
    "done\n",
    "\n",
    "Starting download...\n",
    "\n",
    "Download was successfull!\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================================================\n",
    "# Part 4: Insert regions of interest\n",
    "# =====================================================================================================================\n",
    "\n",
    "print(sep)\n",
    "print('Setting sample for data analysis...')\n",
    "print(sep)\n",
    "\n",
    "if inAreas == '1':\n",
    "    print('Openning MODIS Land Cover product...')\n",
    "    nc = xr.open_dataset(os.path.join(mdir, 'MCD12Q1.006_500m_aid0001.nc'))\n",
    "    nc = nc.isel(time=[0])\n",
    "    nc = nc.drop(['crs', 'QC'])\n",
    "    numClasses = (len(np.unique(nc['LC_Type1'])))\n",
    "    \n",
    "    print('Converting data from NetCDF to Data Frame...')\n",
    "    df = nc['LC_Type1'].to_dataframe()\n",
    "\n",
    "    mCLasses = {0:'Water', 1:'Evergreen Needleleaf Forest', 2:'Evergreen Broadleaf Forest',\n",
    "                3:'Deciduous Needleleaf Forest', 4:'Deciduous Broadleaf Forest',\n",
    "                5:'Mixed Forests', 6:'Closed Shrublands',\n",
    "                7:'Open Shrublands', 8:'Woody Savannas',\n",
    "                9:'Savannas', 10:'Grasslands',\n",
    "                11:'Permanent Wetlands', 12:'Croplands',\n",
    "                13:'Urban and Build-up', 14:'Cropland/Natural Vegetation Mosaic',\n",
    "                15:'Snow and Ice', 16:'Barren or Sparsely Vegetated'}\n",
    "    colorPalette = {'Water':'#001146', 'Evergreen Needleleaf Forest':'#033500',\n",
    "                    'Evergreen Broadleaf Forest':'#06470c', 'Deciduous Needleleaf Forest':'#3f9b0b',\n",
    "                    'Deciduous Broadleaf Forest':'#137e6d', 'Mixed Forests':'#40a368',\n",
    "                    'Closed Shrublands':'#e6daa6', 'Open Shrublands':'#ad8150', \n",
    "                    'Woody Savannas':'#ceb301', 'Savannas':'#9aae07',\n",
    "                    'Grasslands':'#c7fdb5', 'Permanent Wetlands':'#06c2ac',\n",
    "                    'Croplands':'#653700', 'Urban and Build-up':'#516572', \n",
    "                    'Cropland/Natural Vegetation Mosaic':'#a83c09',\n",
    "                    'Snow and Ice':'#ffffff', 'Barren or Sparsely Vegetated':'#e2ca76'}\n",
    "\n",
    "    colorMap = mpl.colors.ListedColormap(['#001146', '#033500', '#06470c', '#3f9b0b', '#137e6d', '#40a368',\n",
    "                                          '#e6daa6', '#ad8150', '#ceb301', '#9aae07', '#c7fdb5', '#06c2ac',\n",
    "                                          '#653700', '#516572', '#a83c09', '#ffffff', '#e2ca76'])\n",
    "    colorNorm = mpl.colors.Normalize(vmin=0,vmax=16)\n",
    "    \n",
    "    print(sep)\n",
    "    df['LandUse'] = df['LC_Type1'].map(mCLasses)\n",
    "    print(df.head())\n",
    "    df = df.reset_index()\n",
    "    print(sep)\n",
    "    \n",
    "    print('Plotting land cover map and size of each class...')\n",
    "    nc['LC_Type1'].plot(add_colorbar=False, cmap=colorMap, norm=colorNorm, size=5)\n",
    "    patchList = []\n",
    "    for key in colorPalette:\n",
    "        data_key = mpl.patches.Patch(color=colorPalette[key], label=key)\n",
    "        patchList.append(data_key)\n",
    "    plt.legend(handles=patchList, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title('Land Cover Map')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.show()\n",
    "\n",
    "    sns.countplot(data=df, y='LandUse', palette=colorPalette)\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('Count')\n",
    "    plt.show()\n",
    "    print(sep)\n",
    "    \n",
    "    # Remove unwanted classes\n",
    "    print('Removing unwanted classes...')\n",
    "    for i in [0, 13, 15, 254, 255]: \n",
    "        dfr = df[df['LC_Type1'] != i]\n",
    "        df = dfr   \n",
    "\n",
    "    counts = dfr['LC_Type1'].value_counts()\n",
    "    nClasses = (counts.index.tolist())\n",
    "    counts = counts.nlargest(4)\n",
    "    lClasses = (counts.index.tolist())\n",
    "    nClasses = list(set(nClasses) - set(lClasses))\n",
    "\n",
    "    # Remove unwanted classes\n",
    "    print('Filtering 4 biggest classes for analysis...')\n",
    "    for i in nClasses: \n",
    "        dfr = dfr[dfr['LC_Type1'] != i]\n",
    "    print('Selected classes for analysis: ', dfr['LandUse'].unique().tolist())\n",
    "    \n",
    "    print('Creating stratified random sample for each class...')\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.01, random_state=1)\n",
    "\n",
    "    for train_index, test_index in split.split(dfr, dfr['LC_Type1']):\n",
    "        sample = dfr.reindex(test_index)\n",
    "        sample = sample.dropna()\n",
    "    print('Sample successfully generated!')\n",
    "    print(sep)\n",
    "        \n",
    "elif inAreas == '2':\n",
    "    print('Loading table with points of interest...')\n",
    "    land_use_points = pd.read_csv(os.path.join(wdir, 'land_use_points.csv'))\n",
    "    geometry = [shapely.geometry.Point(xy) for xy in zip(land_use_points.lon, land_use_points.lat)]\n",
    "    crs = {\"init\": \"epsg:4326\"}\n",
    "    sample = gpd.GeoDataFrame(land_use_points, crs=crs, geometry=geometry)\n",
    "    print('Sample successfully generated!')\n",
    "    print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Setting sample for data analysis...\n",
    "\n",
    "====================================================================================================================\n",
    "Loading table with points of interest...\n",
    "\n",
    "<img src=\"Coords.png\">\n",
    "\n",
    "Sample successfully generated!\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================================================\n",
    "# Part 5 - Part 5 is subdivided into 5.1, 5.2 and 5.3 and opens the netCDF files and extracts the values \n",
    "# for the data frames\n",
    "# =====================================================================================================================\n",
    "# =====================================================================================================================\n",
    "# Part 5.1 - Open netCDF files and extract values to data frames - SMOS\n",
    "# =====================================================================================================================\n",
    "\n",
    "print(sep)\n",
    "print('Processing SMOS data...')\n",
    "for orbit in [\"ASCENDING\"]:\n",
    "    print(sep)\n",
    "    print('Processing {0} data...'.format(orbit))\n",
    "    dfs = []\n",
    "    smdir = os.path.join(sdir, orbit)\n",
    "    flist = os.listdir(smdir)\n",
    "    for file in flist:\n",
    "        nc = xr.open_dataset(os.path.join(smdir, file))\n",
    "\n",
    "        time = file[19:25]\n",
    "        time = datetime.datetime.strptime(time, '%Y%m')\n",
    "        time = xr.DataArray(time)\n",
    "\n",
    "        nc = nc.where((nc.Longitude >= xbl) & (nc.Latitude >= ybl) & (nc.Longitude <= xur) & (nc.Latitude <= yur))\n",
    "        nc = nc.__getitem__([\"Soil_Moisture\"])\n",
    "\n",
    "        print('Calculating mean soil moisture for area of study')\n",
    "        nc = nc.mean(dim=('n_grid_points'), skipna=True)\n",
    "        nc['Time'] = time\n",
    "        nc = nc.expand_dims(\"\")\n",
    "\n",
    "        df = nc.to_dataframe()\n",
    "        dfs.append(df)\n",
    "\n",
    "    dfs = pd.concat(dfs)\n",
    "    dfs.index = pd.to_datetime(dfs['Time'])\n",
    "    print('Filling gaps...')\n",
    "    dfs[\"Soil_Moisture\"].interpolate(method='time', inplace=True)\n",
    "    print('Calculating monthly mean values...')\n",
    "    dfs = dfs.resample('M').mean()\n",
    "    dfs['Time'] = pd.to_datetime(dfs.index)\n",
    "    dfs.index = pd.to_datetime(dfs[\"Time\"], format='%Y%m').apply(lambda x: x.strftime('%Y-%m'))\n",
    "    del dfs['Time']\n",
    "    print('Done!')\n",
    "    print(sep)\n",
    "    print(dfs.head())\n",
    "print(sep)\n",
    "print('Processing complete!')\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Processing SMOS data...\n",
    "\n",
    "====================================================================================================================\n",
    "Processing ASCENDING data...\n",
    "\n",
    "Filling gaps...\n",
    "\n",
    "Calculating monthly mean values...\n",
    "\n",
    "Done!\n",
    "\n",
    "====================================================================================================================\n",
    "<img src=\"SoilMoisture.png\">\n",
    "\n",
    "====================================================================================================================\n",
    "Processing complete!\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================================================\n",
    "# Part 5.2 - Open netCDF files and extract values to data frames - CHIRPS\n",
    "# =====================================================================================================================\n",
    "\n",
    "print(sep)\n",
    "print('Processing CHIRPS data...')\n",
    "print(sep)\n",
    "\n",
    "# Open file\n",
    "nc = xr.open_dataset(filename_or_obj=(cdir + '/chirps-v2.0.monthly.nc'))  \n",
    "\n",
    "print('Slicing data...')\n",
    "ncs = nc.sel(time=slice('2010-06-01', '2018-12-31'), longitude=slice(xbl, xur), latitude=slice(ybl, yur))\n",
    "\n",
    "print('Calculating mean monthly rainfall for study area...')\n",
    "ncs_m = ncs.mean(dim=('latitude', 'longitude'))\n",
    "\n",
    "print('Converting from NetCDF to Data Frame...')\n",
    "dfc = ncs_m.to_dataframe()\n",
    "\n",
    "dfc[\"Time\"] = dfc.index\n",
    "dfc.index = pd.to_datetime(dfc[\"Time\"], format='%Y%m').apply(lambda x: x.strftime('%Y-%m'))\n",
    "del dfc[\"Time\"]\n",
    "\n",
    "print('Done!')\n",
    "print(sep)\n",
    "print(dfc.head())\n",
    "print(sep)\n",
    "print('Processing complete!')\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Processing CHIRPS data...\n",
    "\n",
    "====================================================================================================================\n",
    "Slicing data...\n",
    "\n",
    "Calculating mean monthly rainfall for study area...\n",
    "\n",
    "Converting from NetCDF to Data Frame...\n",
    "\n",
    "Done!\n",
    "\n",
    "====================================================================================================================\n",
    "<img src=\"Precip.png\">\n",
    "\n",
    "====================================================================================================================\n",
    "Processing complete!\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================================================\n",
    "# Part 5.3 - Open netCDF files and extract values to data frames - MODIS\n",
    "# =====================================================================================================================\n",
    "\n",
    "print(sep)\n",
    "print('Processing MODIS data...')\n",
    "print(sep)\n",
    "\n",
    "layers = ['LST_Day_1km', 'Lai_500m', '_1_km_monthly_NDVI', '_1_km_monthly_EVI', 'Gpp_500m']\n",
    "\n",
    "flist = []\n",
    "for file in os.listdir(mdir):\n",
    "    if file.endswith(\".nc\"):\n",
    "        flist.append(file)\n",
    "flist.remove(\"MCD12Q1.006_500m_aid0001.nc\")\n",
    "\n",
    "dfm = []\n",
    "\n",
    "print('Calculating monthly mean values of LST, LAI, NDVI, EVI and GPP for each land cover/points of interest...')\n",
    "row = next(sample.iterrows())\n",
    "for f in flist:\n",
    "    print('Processing {0} data...'.format(f))\n",
    "    nc = xr.open_dataset(filename_or_obj=(os.path.join(mdir, f)))\n",
    "    for c, row in sample.iterrows():\n",
    "        nvar = nc.sel(lon=row['lon'], lat=row['lat'], method='nearest')\n",
    "        df = nvar.to_dataframe()\n",
    "        df.index = df.index.to_datetimeindex()\n",
    "        for l in layers:\n",
    "            try:\n",
    "                df[l].interpolate(method='time', inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "        df = df.resample('M').mean()\n",
    "        df['Time'] = df.index\n",
    "        df.index = pd.to_datetime(df[\"Time\"], format='%Y%m').apply(lambda x: x.strftime('%Y-%m'))\n",
    "        df['Time'] = df.index\n",
    "        df['LandUse'] = row['LandUse']\n",
    "        df.set_index(['Time', 'LandUse'], inplace=True)\n",
    "        dfm.append(df)\n",
    "\n",
    "print('Merging Data Frames...')\n",
    "dfm = pd.concat(dfm, axis=1).sort_index(axis=1)\n",
    "print('Filtering Data Frames...')\n",
    "dfm = dfm[layers]\n",
    "dfm = dfm.groupby(level=0, axis=1).mean()\n",
    "dfm = dfm.dropna()\n",
    "print('Done!')\n",
    "print(sep)\n",
    "print(dfm.head())\n",
    "print(sep)\n",
    "print('Processing complete!')\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Processing MODIS data...\n",
    "\n",
    "====================================================================================================================\n",
    "Calculating monthly mean values of LST, LAI, NDVI, EVI and GPP for each land cover/points of interest...\n",
    "\n",
    "Processing MOD11A2.006_1km_aid0001.nc data...\n",
    "\n",
    "Processing MOD17A2H.006_500m_aid0001.nc data...\n",
    "\n",
    "Processing MOD16A2.006_500m_aid0001.nc data...\n",
    "\n",
    "Processing MOD13A3.006_1km_aid0001.nc data...\n",
    "\n",
    "Processing MOD15A2H.006_500m_aid0001.nc data...\n",
    "\n",
    "Merging Data Frames...\n",
    "\n",
    "Filtering Data Frames...\n",
    "\n",
    "Done!\n",
    "\n",
    "====================================================================================================================\n",
    "<img src=\"MODIS.png\">\n",
    "\n",
    "====================================================================================================================\n",
    "Processing complete!\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sep)\n",
    "print('Merging Data Frames...')\n",
    "print(sep)\n",
    "\n",
    "df = dfm.join(dfc, how='right')\n",
    "df = df.join(dfs, how='right')\n",
    "colnames = ['GPP', 'LST', 'LAI', 'EVI', 'NDVI', 'PRECIP', 'SM']\n",
    "df.columns = colnames\n",
    "df.index = df.index.set_levels([pd.to_datetime(df.index.levels[0]), df.index.levels[1]])\n",
    "df.to_csv(r'' + wdir + '/df' + '.csv')\n",
    "\n",
    "print('Done!')\n",
    "print(sep)\n",
    "print(df.head())\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Merging Data Frames...\n",
    "\n",
    "====================================================================================================================\n",
    "Done!\n",
    "\n",
    "====================================================================================================================\n",
    "<img src=\"Merge.png\">\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================================================================\n",
    "# Part 6 - Data analysis\n",
    "# =====================================================================================================================\n",
    "\n",
    "#Generating time series\n",
    "print(sep)\n",
    "print('Generating time series...')\n",
    "print(sep)\n",
    "\n",
    "dfu = df.unstack()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(20,20), sharex=True)\n",
    "\n",
    "dfu.GPP.plot(ax=axes[0], title='GPP', legend=False)\n",
    "dfu.LAI.plot(ax=axes[1], title='LAI', legend=False)\n",
    "dfu.EVI.plot(ax=axes[2], title='EVI', legend=False)\n",
    "dfu.NDVI.plot(ax=axes[3], title='NDVI', legend=False)\n",
    "dfu.LST.plot(ax=axes[4], title='LST', legend=False)\n",
    "dfu.PRECIP.plot(ax=axes[5], title='PRECIP', legend=False)\n",
    "dfu.SM.plot(ax=axes[6], title='SM', legend=False)\n",
    "\n",
    "lg = axes[0].legend(bbox_to_anchor=(1.02, 1), loc=2, ncol=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Generating time series...\n",
    "\n",
    "====================================================================================================================\n",
    "<img src=\"TimeSeries.png\">\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating time series tendency\n",
    "print(sep)\n",
    "print('Generating time series tendency...')\n",
    "print(sep)\n",
    "\n",
    "dfr = dfu[colnames].rolling(window=12, center=True).mean()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=7, ncols=1, figsize=(20,20), sharex=True)\n",
    "\n",
    "dfr.GPP.plot(ax=axes[0], title='GPP', legend=False)\n",
    "dfr.LAI.plot(ax=axes[1], title='LAI', legend=False)\n",
    "dfr.EVI.plot(ax=axes[2], title='EVI', legend=False)\n",
    "dfr.NDVI.plot(ax=axes[3], title='NDVI', legend=False)\n",
    "dfr.LST.plot(ax=axes[4], title='LST', legend=False)\n",
    "dfr.PRECIP.plot(ax=axes[5], title='PRECIP', legend=False)\n",
    "dfr.SM.plot(ax=axes[6], title='SM', legend=False)\n",
    "\n",
    "lg = axes[0].legend(bbox_to_anchor=(1.02, 1), loc=2, ncol=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Generating tendency series...\n",
    "\n",
    "====================================================================================================================\n",
    "<img src=\"Tendency.png\">\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphics generation\n",
    "print(sep)\n",
    "print('Generating scatter plot between Soil Moisture and MODIS products...')\n",
    "print(sep)\n",
    "\n",
    "dfp = df.reset_index()\n",
    "\n",
    "sns.lmplot(x=\"SM\", y='GPP', hue=\"LandUse\", legend='full', data=dfp, height=4)\n",
    "sns.lmplot(x=\"SM\", y='LAI', hue=\"LandUse\", legend='full', data=dfp, height=4)\n",
    "sns.lmplot(x=\"SM\", y='EVI', hue=\"LandUse\", legend='full', data=dfp, height=4)\n",
    "sns.lmplot(x=\"SM\", y='NDVI', hue=\"LandUse\", legend='full', data=dfp, height=4)\n",
    "sns.lmplot(x=\"SM\", y='LST', hue=\"LandUse\", legend='full', data=dfp, height=4)\n",
    "plt.show()\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Generating scatter plot between Soil Moisture and MODIS products...\n",
    "\n",
    "====================================================================================================================\n",
    "<img src=\"SM1.png\">\n",
    "<img src=\"SM2.png\">\n",
    "<img src=\"SM3.png\">\n",
    "<img src=\"SM4.png\">\n",
    "<img src=\"SM5.png\">\n",
    "\n",
    "===================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphics generation\n",
    "print(sep)\n",
    "print('Generating scatter plot between Precipitation and MODIS products...')\n",
    "print(sep)\n",
    "\n",
    "sns.lmplot(x=\"PRECIP\", y='GPP', hue=\"LandUse\", legend='full', data=dfp, height=4)\n",
    "sns.lmplot(x=\"PRECIP\", y='LAI', hue=\"LandUse\", legend='full', data=dfp, height=4)\n",
    "sns.lmplot(x=\"PRECIP\", y='EVI', hue=\"LandUse\", legend='full', data=dfp, height=4)\n",
    "sns.lmplot(x=\"PRECIP\", y='NDVI', hue=\"LandUse\", legend='full', data=dfp, height=4)\n",
    "sns.lmplot(x=\"PRECIP\", y='LST', hue=\"LandUse\", legend='full', data=dfp, height=4)\n",
    "plt.show()\n",
    "print(sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================================================================\n",
    "Generating scatter plot between Precipitation and MODIS products...\n",
    "\n",
    "====================================================================================================================\n",
    "<img src=\"P1.png\">\n",
    "<img src=\"P2.png\">\n",
    "<img src=\"P3.png\">\n",
    "<img src=\"P4.png\">\n",
    "<img src=\"P5.png\">\n",
    "\n",
    "===================================================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
